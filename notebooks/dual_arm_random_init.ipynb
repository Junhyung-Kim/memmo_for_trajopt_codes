{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openravepy\n",
    "import trajoptpy\n",
    "import json\n",
    "import numpy as np\n",
    "import trajoptpy.kin_utils as ku\n",
    "from trajoptpy.check_traj import traj_is_safe\n",
    "import time\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from trajopt_util import *\n",
    "from planning_util import *\n",
    "from regression import *\n",
    "import trajoptpy.math_utils as mu\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Lock\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FILENAME = 'data/dual_arm_random_init/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the trajopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "env = openravepy.Environment()\n",
    "env.StopSimulation()\n",
    "env.Load(\"robots/pr2-beta-static.zae\")\n",
    "env.Load(\"../env/bookshelves.env.xml\")\n",
    "env.SetDefaultViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_arm_joints(x):\n",
    "    \"mirror image of joints (r->l or l->r)\"\n",
    "    return [-x[0],x[1],-x[2],x[3],-x[4],x[5],-x[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = env.GetRobots()[0]\n",
    "left_arm = robot.GetManipulator(\"leftarm\")\n",
    "right_arm = robot.GetManipulator(\"rightarm\")\n",
    "\n",
    "robot.SetActiveDOFs(np.r_[right_arm.GetArmIndices(), left_arm.GetArmIndices()])\n",
    "coeffs = [1,1,1,1,1,1,1,  1,1,1,1,1,1,1,] #coefficients for joint velocity cost\n",
    "\n",
    "dof = len(robot.GetActiveDOFValues())\n",
    "left_dof_away = np.array([ 0.5646,  1.1371, -0.65  , -2.1172,  2.0552, 0.99, -2.168 ])\n",
    "right_dof_away = np.array([ -0.5646,  1.1371, 0.65  , -2.1172,  2.0552, 0.99, -2.168 ])\n",
    "robot.SetDOFValues(left_dof_away, left_arm.GetArmIndices())\n",
    "robot.SetDOFValues(right_dof_away, right_arm.GetArmIndices())\n",
    "init_joint0 = robot.GetActiveDOFValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_waypoints = [\n",
    "    [-0.043379, 0.103374, -1.6, -2.27679, 3.02165, -2.03223, -1.6209], #chest fwd\n",
    "    [-0.18199, -0.088593, -1.6, -2.08996, 3.04403, -0.41007, -1.39646],# side fwd\n",
    "    [-0.0428341, -0.489164, -0.6, -1.40856, 2.32152, -0.669566, -2.13699],# face up\n",
    "    [0.0397607, 1.18538, -0.8, -0.756239, -2.84594, -1.06418, -2.42207]# floor down\n",
    "]\n",
    "\n",
    "right_waypoints = []\n",
    "for w in left_waypoints:\n",
    "    right_waypoints.append(mirror_arm_joints(w))\n",
    "    \n",
    "waypoints = [init_joint0.copy()]\n",
    "for i in range(len(left_waypoints)):\n",
    "    waypoints.append(right_waypoints[i]+left_waypoints[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the IK Solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmat_target = np.array([[ 0.9689,  0.    , -0.2474,  0.4918],\n",
    "       [-0.    ,  1.    ,  0.    ,  0.912 ],\n",
    "       [ 0.2474, -0.    ,  0.9689,  0.8947],\n",
    "       [ 0.    ,  0.    ,  0.    ,  1.    ]])\n",
    "quat_target = openravepy.quatFromRotationMatrix(hmat_target).tolist()\n",
    "xyz_target = hmat_target[0:3,3].tolist()\n",
    "\n",
    "# BEGIN IK for all manips\n",
    "manips = [left_arm,right_arm]\n",
    "for manip in manips:\n",
    "    robot.SetActiveManipulator(manip)\n",
    "    ikmodel = openravepy.databases.inversekinematics.InverseKinematicsModel(\n",
    "        robot, iktype=openravepy.IkParameterization.Type.Transform6D)\n",
    "    if not ikmodel.load():\n",
    "        ikmodel.autogenerate()   \n",
    "    \n",
    "target_joint = ku.ik_for_link(hmat_target, left_arm, \"l_gripper_tool_frame\",\n",
    "    filter_options = openravepy.IkFilterOptions.CheckEnvCollisions)\n",
    "# END ik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build / Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs(n = 100, filename = 'data.pkl'):\n",
    "    x = []\n",
    "    target_joints = []\n",
    "    for i in range(n):\n",
    "        _,_,_,_,init_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        _,_,_,_,target_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "        robot.SetActiveDOFValues(target_joint)\n",
    "        x.append(np.concatenate([init_joint, target_joint]))\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print i\n",
    "\n",
    "    x = np.vstack(x)\n",
    "    data = dict()\n",
    "    data['x'] = x\n",
    "    input_file = open(filename, 'wb')\n",
    "    pickle.dump(data, input_file)\n",
    "    input_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(x_init, y_init, num_traj, limits,  predictor=None, n_steps = 30, x_train = None):\n",
    "    num_plan = 0\n",
    "    comp_times = []\n",
    "    costs = []\n",
    "    tic = time.time()\n",
    "    \n",
    "    while len(x_init) < num_traj:\n",
    "        print('{}th Planning, {} trajectories in database'.format(num_plan,len(x_init)))\n",
    "        if x_train is None:\n",
    "            #Get a random pose as init\n",
    "            _,_,_,_,init_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "            robot.SetActiveDOFValues(init_joint)\n",
    "            #Get a random pose as target\n",
    "            _,_,_,_,target_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "            robot.SetActiveDOFValues(target_joint)\n",
    "        else:\n",
    "            x_cur = x_train[num_plan]\n",
    "            init_joint = x_cur[:dof]\n",
    "            target_joint = x_cur[dof:]\n",
    "            \n",
    "        #plan\n",
    "        for func in predictor:\n",
    "            x_cur = np.atleast_2d(np.concatenate([init_joint,target_joint]))\n",
    "            if isinstance(func, Straight_Regressor):\n",
    "                traj,_ = func.predict(init_joint, target_joint)\n",
    "            else:\n",
    "                traj,_ = func.predict(x_cur)\n",
    "            if func.is_transform == 'PCA':\n",
    "                traj = func.pca.inverse_transform(traj)\n",
    "            traj = traj.reshape(-1,dof)\n",
    "            traj[0,:] = init_joint\n",
    "            robot.SetActiveDOFValues(init_joint)\n",
    "\n",
    "            request_traj = define_request(time_step =n_steps,coeffs = coeffs,init_type='given_traj',constraint_type='joint')\n",
    "            request_traj = add_constraint(request_traj, 'joint', '', target_joint,-1)\n",
    "            request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "            duration, result = run_opt(request_traj, env)    \n",
    "\n",
    "            #check traj result\n",
    "            traj = result.GetTraj()\n",
    "            if check_traj(env,result, target_joint):\n",
    "                print 'Planning is successfull!'\n",
    "                x_init.append(np.concatenate([init_joint, target_joint]))\n",
    "                y_init.append(traj.flatten())\n",
    "                comp_times.append(duration)\n",
    "                costs.append(result.GetCosts()[0][1])\n",
    "                break\n",
    "            else:\n",
    "                print('Fail to find good solution!')\n",
    "                continue\n",
    "\n",
    "        num_plan += 1\n",
    "        \n",
    "    toc = time.time()\n",
    "    total_time = toc-tic\n",
    "    success_rate = num_traj*1.0/num_plan\n",
    "    x_init = np.vstack(x_init)\n",
    "    y_init = np.vstack(y_init)\n",
    "    \n",
    "    \n",
    "    data = dict()\n",
    "    data['x'] = x_init\n",
    "    data['y'] = y_init\n",
    "    data['total_time'] = total_time\n",
    "    data['success_rate'] = success_rate\n",
    "    data['comp_times'] = comp_times\n",
    "    data['costs'] = costs\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the possible inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_create_input = False\n",
    "if to_create_input:\n",
    "    data_train = generate_inputs(n = 5000, filename = FILENAME + 'data_train.pkl')\n",
    "else:\n",
    "    data_train = pickle.load(open(FILENAME + 'data_train.pkl', 'rb'))\n",
    "    \n",
    "x_train = data_train['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_build_database = False\n",
    "to_augment_database = False\n",
    "n_steps = 30\n",
    "straight = Straight_Regressor(dof = dof, n_steps = n_steps)\n",
    "\n",
    "num_traj = 500\n",
    "limits = dict()\n",
    "limits[0] = [[0.47, 0.8],[-0.5, 0.5],[0.3,1.4]]\n",
    "\n",
    "if to_build_database:\n",
    "    if to_augment_database:\n",
    "        #load data\n",
    "        data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "        x_init = list(data['x'])\n",
    "        y_init = list(data['y'])\n",
    "        x_train = x_train[2*len(x_init):]\n",
    "        num_traj += len(x_init)  \n",
    "    else:\n",
    "        x_init,y_init = [],[]\n",
    "        \n",
    "    data = build_database(x_init, y_init, num_traj,limits, x_train = x_train, predictor = [straight])\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    pickle.dump(data,open(FILENAME + 'data.pkl', 'wb') )\n",
    "    print('Success_rate : {}, average costs:{}'.format(data['success_rate'], np.mean(data['costs'])))\n",
    "else:\n",
    "    #load data\n",
    "    data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    num_traj = len(x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REDUCED = 1000\n",
    "FILENAME_REDUCED = FILENAME + str(N_REDUCED) + '_'\n",
    "x_init = x_init[0:N_REDUCED]\n",
    "y_init = y_init[0:N_REDUCED]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Dimensionality Reduction to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "y_pca = PCA(n_components = 50)\n",
    "y_pca.fit(y_init)\n",
    "y_init_reduced = y_pca.transform(y_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Database "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(5):\n",
    "    index = np.random.randint(0,len(y_init))\n",
    "    traj = y_init[index:index+1]\n",
    "    traj = traj.reshape(-1,dof)\n",
    "    plot_traj(env,traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Function Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = len(x_init[0])\n",
    "is_load_regressor = False\n",
    "\n",
    "nn = NN_Regressor()\n",
    "gpy = GPy_Regressor(dim_input = dim_input)\n",
    "gpy_pca = GPy_Regressor(dim_input = dim_input, is_transform='PCA')\n",
    "gpy_pca.pca = y_pca\n",
    "bgmr = DP_GLM_Regressor()\n",
    "bgmr_pca = DP_GLM_Regressor(is_transform='PCA')\n",
    "bgmr_pca.pca = y_pca\n",
    "\n",
    "if is_load_regressor:\n",
    "    nn.load_from_file(FILENAME_REDUCED + 'nn.pkl')\n",
    "    gpy.load_from_file(FILENAME_REDUCED + 'gpy.pkl')\n",
    "    gpy_pca.load_from_file(FILENAME_REDUCED + 'gpy_pca.pkl')\n",
    "    bgmr.load_from_file(FILENAME_REDUCED + 'bgmr.pkl')\n",
    "    bgmr_pca.load_from_file(FILENAME_REDUCED + 'bgmr_pca.pkl')\n",
    "else:\n",
    "    print 'Planning for NN'\n",
    "    nn.fit(x_init, y_init)\n",
    "    nn.save_to_file(FILENAME_REDUCED + 'nn.pkl')\n",
    "\n",
    "    print 'Planning for GPY'\n",
    "    gpy.fit(x_init, y_init)\n",
    "    gpy.save_to_file(FILENAME_REDUCED + 'gpy.pkl')\n",
    "\n",
    "    print 'Planning for GPY PCA'\n",
    "    gpy_pca.fit(x_init, y_init_reduced)\n",
    "    gpy_pca.save_to_file(FILENAME_REDUCED + 'gpy_pca.pkl')\n",
    "\n",
    "    print 'Planning for bgmr'\n",
    "    bgmr.fit(x_init,y_init)\n",
    "    bgmr.save_to_file(FILENAME_REDUCED + 'bgmr.pkl')\n",
    "    \n",
    "    print 'Planning for bgmr PCA'\n",
    "    bgmr_pca.fit(x_init,y_init_reduced)\n",
    "    bgmr_pca.save_to_file(FILENAME_REDUCED + 'bgmr_pca.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_test = False\n",
    "\n",
    "if create_test:\n",
    "    num_test = 300\n",
    "    data_test = generate_inputs(num_test, FILENAME + 'data_test.pkl')\n",
    "    x_test = data_test['x']\n",
    "else:\n",
    "    #load data\n",
    "    test_file = open(FILENAME + 'data_test.pkl', 'rb')\n",
    "    data_test = pickle.load(test_file)\n",
    "    x_test = data_test['x']\n",
    "    num_test = len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Parallel Programming for Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "mutex = Lock()\n",
    "   \n",
    "def run_opt_special(request):\n",
    "    robot.SetActiveDOFValues(init_joint)\n",
    "    s = json.dumps(request) \n",
    "    prob = trajoptpy.ConstructProblem(s, env)\n",
    "    tic = time.time()\n",
    "    try:\n",
    "        result = trajoptpy.OptimizeProblem(prob) # do optimization\n",
    "    except:\n",
    "        print 'Fault in optimization'\n",
    "        return False, None, None, None\n",
    "    toc = time.time()\n",
    "    print(\"Optimization is completed in {} s!\".format(toc-tic))\n",
    "    duration = toc-tic\n",
    "    \n",
    "    #check the result\n",
    "    try:\n",
    "        success = check_traj(env,result, target_joint)    \n",
    "        result_new = dict()\n",
    "        result_new['traj'] = result.GetTraj()\n",
    "        result_new['costs'] = result.GetCosts()[0][1]\n",
    "        cost = result.GetCosts()[0][1]\n",
    "        result_new['status'] = result.GetStatus()\n",
    "        return success, duration, cost, result_new\n",
    "    except:\n",
    "        'Got an exception when checking the trajectory'\n",
    "        return False, None, None, None\n",
    "    \n",
    "def function_callback(result):\n",
    "    with mutex:\n",
    "        print 'Obtain result:'\n",
    "        print result[0]\n",
    "        global count_proc\n",
    "        global num_proc\n",
    "        count_proc+= 1\n",
    "        global ensemble_result\n",
    "        ensemble_result = result\n",
    "        print count_proc, num_proc\n",
    "        if result[0]:\n",
    "            print 'Terminating the mp'\n",
    "            pool.terminate()\n",
    "            return\n",
    "        if count_proc == num_proc:\n",
    "            print 'All fails, terminating the mp'\n",
    "            pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planning_util import print_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['STD    ', 'NN      ', 'GPR    ', 'GPR_PCA', 'BGMR', 'BGMR_PCA', 'ensemble', 'waypoints']\n",
    "methods = [straight, nn, gpy, gpy_pca, bgmr, bgmr_pca]\n",
    "#method_names = ['STD    ', 'NN      ', 'GPR    ',  'ensemble', 'waypoints']\n",
    "#methods = [straight, nn, gpy]\n",
    "\n",
    "results = dict()\n",
    "ensemble_result = None\n",
    "for method in method_names:\n",
    "    results[method] = dict()\n",
    "    results[method]['costs'] = []\n",
    "    results[method]['successes'] = []\n",
    "    results[method]['comp_times'] = []\n",
    "    results[method]['func_evals'] = []\n",
    "    results[method]['qp_solves'] = []\n",
    "\n",
    "result,success, duration = dict(),dict(),dict()\n",
    "num_test = 100\n",
    "for it in range(0,num_test):\n",
    "    print('{}th Planning'.format(it))\n",
    "    \n",
    "    #setting up the problem case\n",
    "    index = np.random.randint(0,len(x_test))\n",
    "    index = it\n",
    "    x_cur = x_test[index:index+1,:].flatten()\n",
    "    init_joint = x_cur.copy()[0:dof]\n",
    "    target_joint = x_cur.copy()[dof:]\n",
    "    robot.SetActiveDOFValues(init_joint)\n",
    "    \n",
    "    \n",
    "    x_cur = np.atleast_2d(np.concatenate([init_joint,target_joint]))\n",
    "    request_trajs = []\n",
    "    for i,method in enumerate(methods):\n",
    "        request_traj = define_request(coeffs = coeffs,init_type='given_traj',constraint_type='joint')\n",
    "        request_traj = add_constraint(request_traj, 'joint', '', target_joint,-1)\n",
    "        method_name = method_names[i]\n",
    "        if isinstance(method, Straight_Regressor):\n",
    "            traj,_ = method.predict(init_joint, target_joint)\n",
    "        else:\n",
    "            traj,cov = method.predict(x_cur)\n",
    "        if method.is_transform == 'PCA':\n",
    "            traj = method.pca.inverse_transform(traj)\n",
    "        traj = traj.reshape(-1,dof)\n",
    "        traj[0,:] = init_joint\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "        success[method_name], duration[method_name], _, result[method_name] = run_opt_special(request_traj)    \n",
    "        request_trajs.append(request_traj)\n",
    "\n",
    "    \n",
    "    #ensemble methods   \n",
    "    print(\"Start ensemble\")\n",
    "    num_proc = len(request_trajs)\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    count_proc = 0\n",
    "    ticc = time.time()\n",
    "    for request in request_trajs:\n",
    "        pool.apply_async(run_opt_special, args = (request, ), callback = function_callback)\n",
    "    time.sleep(5)\n",
    "    pool.terminate()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    tocc = time.time()\n",
    "    print 'Ensemble takes ' + str(tocc-ticc)\n",
    "    results['ensemble']['costs'].append(ensemble_result[2])\n",
    "    results['ensemble']['successes'].append(ensemble_result[0])      \n",
    "    results['ensemble']['comp_times'].append(tocc-ticc)\n",
    "    \n",
    "    #multiple_waypoints\n",
    "    print(\"Start multiple waypoints\")\n",
    "    cur_waypoints = list(waypoints)\n",
    "    cur_waypoints.append(0.5*(init_joint+target_joint))\n",
    "    num_proc = len(cur_waypoints)\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    count_proc = 0\n",
    "    ticc = time.time()\n",
    "    #create request_trajs\n",
    "    request_trajs = []\n",
    "    for j in range(num_proc):\n",
    "        waypoint = cur_waypoints[j]\n",
    "        request_traj = define_request(coeffs = coeffs,init_type='given_traj',constraint_type='joint')\n",
    "        request_traj = add_constraint(request_traj, 'joint', '', target_joint,-1)\n",
    "        method_name = 'waypoints'\n",
    "        traj,_ = straight.predict_with_waypoint(init_joint, target_joint, waypoint, n_steps/2 )\n",
    "        traj = traj.reshape(-1,dof)\n",
    "        traj[0,:] = init_joint\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "        request_trajs.append(request_traj)\n",
    "    \n",
    "    #run request_trajs\n",
    "    for request in request_trajs:\n",
    "        pool.apply_async(run_opt_special, args = (request, ), callback = function_callback)\n",
    "    time.sleep(5)\n",
    "    pool.terminate()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    tocc = time.time()\n",
    "    print 'Multiple waypoints takes ' + str(tocc-ticc)\n",
    "    results['waypoints']['costs'].append(ensemble_result[2])\n",
    "    results['waypoints']['successes'].append(ensemble_result[0])      \n",
    "    results['waypoints']['comp_times'].append(tocc-ticc)\n",
    "    \n",
    "    #Record the result\n",
    "    for method_name in method_names[:-2]:\n",
    "        results[method_name]['costs'].append(result[method_name]['costs'])#.GetCosts())#[0][1])\n",
    "        results[method_name]['successes'].append(success[method_name])      \n",
    "        results[method_name]['comp_times'].append(duration[method_name])\n",
    "        \n",
    "    print_result(results,method_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(results, method_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results,open(FILENAME_REDUCED + 'result.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open(FILENAME_REDUCED + 'result.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
